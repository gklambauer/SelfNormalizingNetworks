{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Tutorial on self-normalizing networks on the MNIST data set: convolutional neural networks\n",
    "\n",
    "*Author:* Guenter Klambauer, 2017\n",
    "\n",
    "tested under Python 3.5 and Tensorflow 1.1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "from __future__ import absolute_import, division, print_function\n",
    "import numbers\n",
    "from tensorflow.contrib import layers\n",
    "from tensorflow.python.framework import ops\n",
    "from tensorflow.python.framework import tensor_shape\n",
    "from tensorflow.python.framework import tensor_util\n",
    "from tensorflow.python.ops import math_ops\n",
    "from tensorflow.python.ops import random_ops\n",
    "from tensorflow.python.ops import array_ops\n",
    "from tensorflow.python.layers import utils\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.special import erf,erfc\n",
    "\n",
    "# Import MNIST data\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"/tmp/data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Add desired fixed point here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "alpha01 = - np.sqrt(2/np.pi) / (np.exp(0.5) * erfc(1/np.sqrt(2))-1 )  \n",
    "lambda01 = (1-np.sqrt(np.exp(1))*erfc(1/np.sqrt(2)))  *  \\\n",
    "                np.sqrt( 2*np.pi/ (2 + np.pi -2*np.sqrt(np.exp(1))*(2+np.pi) *  \\\n",
    "                erfc(1/np.sqrt(2)) + np.exp(1)*np.pi*erfc(1/np.sqrt(2))**2 + 2*np.exp(2)*erfc(np.sqrt(2))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0507009873554807"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lambda01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1) Definition of scaled exponential linear units (SELUs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def selu(x):\n",
    "    with ops.name_scope('elu') as scope:\n",
    "        alpha = 1.6732632423543772848170429916717\n",
    "        scale = 1.0507009873554804934193349852946\n",
    "        return scale*tf.where(x>=0.0, x, alpha*tf.nn.elu(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2) Definition of dropout variant for SNNs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def dropout_selu(x, rate, alpha=-1.7580993408473766, noise_shape=None, seed=None, name=None, training=False):\n",
    "    \"\"\"Dropout to a value with rescaling.\"\"\"\n",
    "\n",
    "    def dropout_selu_impl(x, rate, alpha, noise_shape, seed, name):\n",
    "        keep_prob = 1.0 - rate\n",
    "        x = ops.convert_to_tensor(x, name=\"x\")\n",
    "        if isinstance(keep_prob, numbers.Real) and not 0 < keep_prob <= 1:\n",
    "            raise ValueError(\"keep_prob must be a scalar tensor or a float in the \"\n",
    "                                             \"range (0, 1], got %g\" % keep_prob)\n",
    "        keep_prob = ops.convert_to_tensor(keep_prob, dtype=x.dtype, name=\"keep_prob\")\n",
    "        keep_prob.get_shape().assert_is_compatible_with(tensor_shape.scalar())\n",
    "\n",
    "        alpha = ops.convert_to_tensor(alpha, dtype=x.dtype, name=\"alpha\")\n",
    "        keep_prob.get_shape().assert_is_compatible_with(tensor_shape.scalar())\n",
    "\n",
    "        # Do nothing if we know keep_prob == 1\n",
    "        if tensor_util.constant_value(keep_prob) == 1:\n",
    "            return x\n",
    "\n",
    "        noise_shape = noise_shape if noise_shape is not None else array_ops.shape(x)\n",
    "        # uniform [keep_prob, 1.0 + keep_prob)\n",
    "        random_tensor = keep_prob\n",
    "        random_tensor += random_ops.random_uniform(noise_shape, seed=seed, dtype=x.dtype)\n",
    "        # 0. if [keep_prob, 1.0) and 1. if [1.0, 1.0 + keep_prob)\n",
    "        binary_tensor = math_ops.floor(random_tensor)\n",
    "        #binary_tensor2 = math_ops.ceil(random_tensor)\n",
    "        ret = x * binary_tensor + alpha * (1-binary_tensor)\n",
    "\n",
    "        #a = tf.sqrt(1.0/(keep_prob+alpha^2*keep_prob*(1.0-keep_prob)))\n",
    "        a = tf.sqrt(1.0 / keep_prob + tf.pow(alpha,2) * keep_prob * 1.0 - keep_prob)\n",
    "        #a = tf.sqrt(tf.div(1.0, tf.add(keep_prob ,tf.multiply(tf.pow(alpha,2) , tf.multiply(keep_prob,    tf.subtract(1.0,keep_prob)))) ))\n",
    "\n",
    "        b = -a * (1 - keep_prob) * alpha\n",
    "        #b = tf.neg( tf.mul(a , (tf.multiply(tf.subtract(1.0,keep_prob),alpha))))\n",
    "        ret = a * ret + b\n",
    "        #ret = tf.add(tf.multiply(a , ret) , b)\n",
    "        ret.set_shape(x.get_shape())\n",
    "        return ret\n",
    "\n",
    "    with ops.name_scope(name, \"dropout\", [x]) as name:\n",
    "        return utils.smart_cond(training,\n",
    "            lambda: dropout_selu_impl(x, rate, alpha, noise_shape, seed, name),\n",
    "            lambda: array_ops.identity(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (3) Scale input to zero mean and unit variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler().fit(mnist.train.images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "learning_rate = 0.025\n",
    "training_iters = 50\n",
    "batch_size = 128\n",
    "display_step = 1\n",
    "\n",
    "# Network Parameters\n",
    "n_input = 784 # MNIST data input (img shape: 28*28)\n",
    "n_classes = 10 # MNIST total classes (0-9 digits)\n",
    "keep_prob_ReLU = 0.75 # Dropout, probability to keep units\n",
    "dropout_prob_SNN = 0.05 # Dropout, probability to dropout units\n",
    "\n",
    "# tf Graph input\n",
    "x = tf.placeholder(tf.float32, [None, n_input])\n",
    "y = tf.placeholder(tf.float32, [None, n_classes])\n",
    "keep_prob = tf.placeholder(tf.float32) #dropout (keep probability for ReLU)\n",
    "dropout_prob =  tf.placeholder(tf.float32) #dropout (dropout probability for SNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create some wrappers for simplicity\n",
    "def conv2d(x, W, b, strides=1):\n",
    "    # Conv2D wrapper, with bias and relu activation\n",
    "    x = tf.nn.conv2d(x, W, strides=[1, strides, strides, 1], padding='SAME')\n",
    "    x = tf.nn.bias_add(x, b)\n",
    "    return tf.nn.relu(x)\n",
    "\n",
    "def conv2d_SNN(x, W, b, strides=1):\n",
    "    # Conv2D wrapper, with bias and relu activation\n",
    "    x = tf.nn.conv2d(x, W, strides=[1, strides, strides, 1], padding='SAME')\n",
    "    x = tf.nn.bias_add(x, b)\n",
    "    return selu(x)\n",
    "\n",
    "def maxpool2d(x, k=2):\n",
    "    # MaxPool2D wrapper\n",
    "    return tf.nn.max_pool(x, ksize=[1, k, k, 1], strides=[1, k, k, 1],\n",
    "                          padding='SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create model\n",
    "def conv_net_ReLU(x, weights, biases, keep_prob):\n",
    "    # Reshape input picture\n",
    "    x = tf.reshape(x, shape=[-1, 28, 28, 1])\n",
    "\n",
    "    # Convolution Layer\n",
    "    conv1 = conv2d(x, weights['wc1'], biases['bc1'])\n",
    "    # Max Pooling (down-sampling)\n",
    "    conv1 = maxpool2d(conv1, k=2)\n",
    "\n",
    "    # Convolution Layer\n",
    "    conv2 = conv2d(conv1, weights['wc2'], biases['bc2'])\n",
    "    # Max Pooling (down-sampling)\n",
    "    conv2 = maxpool2d(conv2, k=2)\n",
    "\n",
    "    # Fully connected layer\n",
    "    # Reshape conv2 output to fit fully connected layer input\n",
    "    fc1 = tf.reshape(conv2, [-1, weights['wd1'].get_shape().as_list()[0]])\n",
    "    fc1 = tf.add(tf.matmul(fc1, weights['wd1']), biases['bd1'])\n",
    "    fc1 = tf.nn.relu(fc1)\n",
    "    \n",
    "    # Apply Dropout\n",
    "    fc1 = tf.nn.dropout(fc1, keep_prob)\n",
    "\n",
    "    # Output, class prediction\n",
    "    out = tf.add(tf.matmul(fc1, weights['out']), biases['out'])\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create model\n",
    "def conv_net_SNN(x, weights, biases, dropout_prob):\n",
    "    # Reshape input picture\n",
    "    x = tf.reshape(x, shape=[-1, 28, 28, 1])\n",
    "\n",
    "    # Convolution Layer\n",
    "    conv1 = conv2d_SNN(x, weights['wc1'], biases['bc1'],)\n",
    "    # Max Pooling (down-sampling)\n",
    "    conv1 = maxpool2d(conv1, k=2)\n",
    "\n",
    "    # Convolution Layer\n",
    "    conv2 = conv2d_SNN(conv1, weights['wc2'], biases['bc2'])\n",
    "    # Max Pooling (down-sampling)\n",
    "    conv2 = maxpool2d(conv2, k=2)\n",
    "\n",
    "    # Fully connected layer\n",
    "    # Reshape conv2 output to fit fully connected layer input\n",
    "    fc1 = tf.reshape(conv2, [-1, weights['wd1'].get_shape().as_list()[0]])\n",
    "    fc1 = tf.add(tf.matmul(fc1, weights['wd1']), biases['bd1'])\n",
    "    fc1 = selu(fc1)\n",
    "    \n",
    "    # Apply Dropout\n",
    "    fc1 = dropout_selu(fc1, dropout_prob)\n",
    "\n",
    "    # Output, class prediction\n",
    "    out = tf.add(tf.matmul(fc1, weights['out']), biases['out'])\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# RELU: Store layers weight & bias\n",
    "## Improved with MSRA initialization\n",
    "\n",
    "weights = {\n",
    "    # 5x5 conv, 1 input, 32 outputs\n",
    "    'wc1': tf.Variable(tf.random_normal([5, 5, 1, 32],stddev=np.sqrt(2/25)) ),\n",
    "    # 5x5 conv, 32 inputs, 64 outputs\n",
    "    'wc2': tf.Variable(tf.random_normal([5, 5, 32, 64],stddev=np.sqrt(2/(25*32)))),\n",
    "    # fully connected, 7*7*64 inputs, 1024 outputs\n",
    "    'wd1': tf.Variable(tf.random_normal([7*7*64, 1024],stddev=np.sqrt(2/(7*7*64)))),\n",
    "    # 1024 inputs, 10 outputs (class prediction)\n",
    "    'out': tf.Variable(tf.random_normal([1024, n_classes],stddev=np.sqrt(2/(1024))))\n",
    "}\n",
    "\n",
    "biases = {\n",
    "    'bc1': tf.Variable(tf.random_normal([32],stddev=0)),\n",
    "    'bc2': tf.Variable(tf.random_normal([64],stddev=0)),\n",
    "    'bd1': tf.Variable(tf.random_normal([1024],stddev=0)),\n",
    "    'out': tf.Variable(tf.random_normal([n_classes],stddev=0))\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (4) Initialization with STDDEV of sqrt(1/n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# SNN: Store layers weight & bias\n",
    "weights2 = {\n",
    "    # 5x5 conv, 1 input, 32 outputs\n",
    "    'wc1': tf.Variable(tf.random_normal([5, 5, 1, 32],stddev=np.sqrt(1/25)) ),\n",
    "    # 5x5 conv, 32 inputs, 64 outputs\n",
    "    'wc2': tf.Variable(tf.random_normal([5, 5, 32, 64],stddev=np.sqrt(1/(25*32)))),\n",
    "    # fully connected, 7*7*64 inputs, 1024 outputs\n",
    "    'wd1': tf.Variable(tf.random_normal([7*7*64, 1024],stddev=np.sqrt(1/(7*7*64)))),\n",
    "    # 1024 inputs, 10 outputs (class prediction)\n",
    "    'out': tf.Variable(tf.random_normal([1024, n_classes],stddev=np.sqrt(1/(1024))))\n",
    "}\n",
    "\n",
    "biases2 = {\n",
    "    'bc1': tf.Variable(tf.random_normal([32],stddev=0)),\n",
    "    'bc2': tf.Variable(tf.random_normal([64],stddev=0)),\n",
    "    'bd1': tf.Variable(tf.random_normal([1024],stddev=0)),\n",
    "    'out': tf.Variable(tf.random_normal([n_classes],stddev=0))\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Construct model\n",
    "pred_ReLU = conv_net_ReLU(x, weights, biases, keep_prob)\n",
    "pred_SNN = conv_net_SNN(x, weights2, biases2, dropout_prob)\n",
    "\n",
    "# Define loss and optimizer\n",
    "cost_ReLU = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=pred_ReLU, labels=y))\n",
    "cost_SNN = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=pred_SNN, labels=y))\n",
    "\n",
    "optimizer_ReLU = tf.train.GradientDescentOptimizer(learning_rate=learning_rate).minimize(cost_ReLU)\n",
    "optimizer_SNN = tf.train.GradientDescentOptimizer(learning_rate=learning_rate).minimize(cost_SNN)\n",
    "\n",
    "# Evaluate ReLU model\n",
    "correct_pred_ReLU = tf.equal(tf.argmax(pred_ReLU, 1), tf.argmax(y, 1))\n",
    "accuracy_ReLU = tf.reduce_mean(tf.cast(correct_pred_ReLU, tf.float32))\n",
    "\n",
    "# Evaluate SNN model\n",
    "correct_pred_SNN = tf.equal(tf.argmax(pred_SNN, 1), tf.argmax(y, 1))\n",
    "accuracy_SNN = tf.reduce_mean(tf.cast(correct_pred_SNN, tf.float32))\n",
    "\n",
    "\n",
    "# Initializing the variables\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_loss_protocol_ReLU = []\n",
    "training_loss_protocol_SNN = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RELU: Nbr of updates: 1, Minibatch Loss= 2.720972, Training Accuracy= 0.10156\n",
      "SNN: Nbr of updates: 1, Minibatch Loss= 1.569049, Training Accuracy= 0.45312\n",
      "RELU: Nbr of updates: 2, Minibatch Loss= 2.272902, Training Accuracy= 0.22656\n",
      "SNN: Nbr of updates: 2, Minibatch Loss= 2.626802, Training Accuracy= 0.53125\n",
      "RELU: Nbr of updates: 3, Minibatch Loss= 2.229953, Training Accuracy= 0.28125\n",
      "SNN: Nbr of updates: 3, Minibatch Loss= 1.726239, Training Accuracy= 0.58594\n",
      "RELU: Nbr of updates: 4, Minibatch Loss= 1.894720, Training Accuracy= 0.48438\n",
      "SNN: Nbr of updates: 4, Minibatch Loss= 0.701736, Training Accuracy= 0.80469\n",
      "RELU: Nbr of updates: 5, Minibatch Loss= 1.672306, Training Accuracy= 0.61719\n",
      "SNN: Nbr of updates: 5, Minibatch Loss= 0.597832, Training Accuracy= 0.83594\n",
      "RELU: Nbr of updates: 6, Minibatch Loss= 1.497246, Training Accuracy= 0.55469\n",
      "SNN: Nbr of updates: 6, Minibatch Loss= 0.485961, Training Accuracy= 0.90625\n",
      "RELU: Nbr of updates: 7, Minibatch Loss= 1.451231, Training Accuracy= 0.66406\n",
      "SNN: Nbr of updates: 7, Minibatch Loss= 0.422541, Training Accuracy= 0.89062\n",
      "RELU: Nbr of updates: 8, Minibatch Loss= 1.450314, Training Accuracy= 0.68750\n",
      "SNN: Nbr of updates: 8, Minibatch Loss= 0.517356, Training Accuracy= 0.84375\n",
      "RELU: Nbr of updates: 9, Minibatch Loss= 1.305660, Training Accuracy= 0.65625\n",
      "SNN: Nbr of updates: 9, Minibatch Loss= 0.318516, Training Accuracy= 0.94531\n",
      "RELU: Nbr of updates: 10, Minibatch Loss= 1.268677, Training Accuracy= 0.79688\n",
      "SNN: Nbr of updates: 10, Minibatch Loss= 0.414705, Training Accuracy= 0.86719\n",
      "RELU: Nbr of updates: 11, Minibatch Loss= 1.185814, Training Accuracy= 0.76562\n",
      "SNN: Nbr of updates: 11, Minibatch Loss= 0.368448, Training Accuracy= 0.92969\n",
      "RELU: Nbr of updates: 12, Minibatch Loss= 1.126094, Training Accuracy= 0.66406\n",
      "SNN: Nbr of updates: 12, Minibatch Loss= 0.298474, Training Accuracy= 0.93750\n",
      "RELU: Nbr of updates: 13, Minibatch Loss= 1.131941, Training Accuracy= 0.62500\n",
      "SNN: Nbr of updates: 13, Minibatch Loss= 0.374245, Training Accuracy= 0.89844\n",
      "RELU: Nbr of updates: 14, Minibatch Loss= 1.325570, Training Accuracy= 0.59375\n",
      "SNN: Nbr of updates: 14, Minibatch Loss= 0.303229, Training Accuracy= 0.92188\n",
      "RELU: Nbr of updates: 15, Minibatch Loss= 1.169778, Training Accuracy= 0.72656\n",
      "SNN: Nbr of updates: 15, Minibatch Loss= 0.388425, Training Accuracy= 0.90625\n",
      "RELU: Nbr of updates: 16, Minibatch Loss= 0.990541, Training Accuracy= 0.75000\n",
      "SNN: Nbr of updates: 16, Minibatch Loss= 0.347122, Training Accuracy= 0.90625\n",
      "RELU: Nbr of updates: 17, Minibatch Loss= 0.884434, Training Accuracy= 0.80469\n",
      "SNN: Nbr of updates: 17, Minibatch Loss= 0.260720, Training Accuracy= 0.94531\n",
      "RELU: Nbr of updates: 18, Minibatch Loss= 0.960454, Training Accuracy= 0.65625\n",
      "SNN: Nbr of updates: 18, Minibatch Loss= 0.252658, Training Accuracy= 0.96875\n",
      "RELU: Nbr of updates: 19, Minibatch Loss= 0.880230, Training Accuracy= 0.78906\n",
      "SNN: Nbr of updates: 19, Minibatch Loss= 0.199362, Training Accuracy= 0.97656\n",
      "RELU: Nbr of updates: 20, Minibatch Loss= 0.782163, Training Accuracy= 0.85938\n",
      "SNN: Nbr of updates: 20, Minibatch Loss= 0.248098, Training Accuracy= 0.95312\n",
      "RELU: Nbr of updates: 21, Minibatch Loss= 0.765827, Training Accuracy= 0.82031\n",
      "SNN: Nbr of updates: 21, Minibatch Loss= 0.261476, Training Accuracy= 0.93750\n",
      "RELU: Nbr of updates: 22, Minibatch Loss= 0.770471, Training Accuracy= 0.83594\n",
      "SNN: Nbr of updates: 22, Minibatch Loss= 0.251912, Training Accuracy= 0.96094\n",
      "RELU: Nbr of updates: 23, Minibatch Loss= 0.779598, Training Accuracy= 0.78125\n",
      "SNN: Nbr of updates: 23, Minibatch Loss= 0.257677, Training Accuracy= 0.91406\n",
      "RELU: Nbr of updates: 24, Minibatch Loss= 0.796053, Training Accuracy= 0.75781\n",
      "SNN: Nbr of updates: 24, Minibatch Loss= 0.278088, Training Accuracy= 0.92969\n",
      "RELU: Nbr of updates: 25, Minibatch Loss= 0.691283, Training Accuracy= 0.85938\n",
      "SNN: Nbr of updates: 25, Minibatch Loss= 0.203673, Training Accuracy= 0.96875\n",
      "RELU: Nbr of updates: 26, Minibatch Loss= 0.638615, Training Accuracy= 0.85156\n",
      "SNN: Nbr of updates: 26, Minibatch Loss= 0.185276, Training Accuracy= 0.96094\n",
      "RELU: Nbr of updates: 27, Minibatch Loss= 0.587165, Training Accuracy= 0.85938\n",
      "SNN: Nbr of updates: 27, Minibatch Loss= 0.241375, Training Accuracy= 0.96875\n",
      "RELU: Nbr of updates: 28, Minibatch Loss= 0.636230, Training Accuracy= 0.83594\n",
      "SNN: Nbr of updates: 28, Minibatch Loss= 0.225535, Training Accuracy= 0.95312\n",
      "RELU: Nbr of updates: 29, Minibatch Loss= 0.692943, Training Accuracy= 0.78906\n",
      "SNN: Nbr of updates: 29, Minibatch Loss= 0.214595, Training Accuracy= 0.92969\n",
      "RELU: Nbr of updates: 30, Minibatch Loss= 0.673216, Training Accuracy= 0.86719\n",
      "SNN: Nbr of updates: 30, Minibatch Loss= 0.266725, Training Accuracy= 0.94531\n",
      "RELU: Nbr of updates: 31, Minibatch Loss= 0.703637, Training Accuracy= 0.83594\n",
      "SNN: Nbr of updates: 31, Minibatch Loss= 0.298076, Training Accuracy= 0.93750\n",
      "RELU: Nbr of updates: 32, Minibatch Loss= 0.471186, Training Accuracy= 0.89844\n",
      "SNN: Nbr of updates: 32, Minibatch Loss= 0.148115, Training Accuracy= 0.97656\n",
      "RELU: Nbr of updates: 33, Minibatch Loss= 0.531960, Training Accuracy= 0.86719\n",
      "SNN: Nbr of updates: 33, Minibatch Loss= 0.182907, Training Accuracy= 0.95312\n",
      "RELU: Nbr of updates: 34, Minibatch Loss= 0.484118, Training Accuracy= 0.90625\n",
      "SNN: Nbr of updates: 34, Minibatch Loss= 0.193014, Training Accuracy= 0.96875\n",
      "RELU: Nbr of updates: 35, Minibatch Loss= 0.520586, Training Accuracy= 0.88281\n",
      "SNN: Nbr of updates: 35, Minibatch Loss= 0.174057, Training Accuracy= 0.96094\n",
      "RELU: Nbr of updates: 36, Minibatch Loss= 0.459049, Training Accuracy= 0.88281\n",
      "SNN: Nbr of updates: 36, Minibatch Loss= 0.137451, Training Accuracy= 0.98438\n",
      "RELU: Nbr of updates: 37, Minibatch Loss= 0.555395, Training Accuracy= 0.85156\n",
      "SNN: Nbr of updates: 37, Minibatch Loss= 0.166703, Training Accuracy= 0.96094\n",
      "RELU: Nbr of updates: 38, Minibatch Loss= 0.517740, Training Accuracy= 0.88281\n",
      "SNN: Nbr of updates: 38, Minibatch Loss= 0.204360, Training Accuracy= 0.95312\n",
      "RELU: Nbr of updates: 39, Minibatch Loss= 0.676205, Training Accuracy= 0.75781\n",
      "SNN: Nbr of updates: 39, Minibatch Loss= 0.247705, Training Accuracy= 0.92188\n",
      "RELU: Nbr of updates: 40, Minibatch Loss= 0.544066, Training Accuracy= 0.83594\n",
      "SNN: Nbr of updates: 40, Minibatch Loss= 0.216793, Training Accuracy= 0.95312\n",
      "RELU: Nbr of updates: 41, Minibatch Loss= 0.362943, Training Accuracy= 0.92969\n",
      "SNN: Nbr of updates: 41, Minibatch Loss= 0.142694, Training Accuracy= 0.96875\n",
      "RELU: Nbr of updates: 42, Minibatch Loss= 0.441487, Training Accuracy= 0.91406\n",
      "SNN: Nbr of updates: 42, Minibatch Loss= 0.189054, Training Accuracy= 0.95312\n",
      "RELU: Nbr of updates: 43, Minibatch Loss= 0.486949, Training Accuracy= 0.84375\n",
      "SNN: Nbr of updates: 43, Minibatch Loss= 0.201976, Training Accuracy= 0.92188\n",
      "RELU: Nbr of updates: 44, Minibatch Loss= 0.365758, Training Accuracy= 0.92188\n",
      "SNN: Nbr of updates: 44, Minibatch Loss= 0.142311, Training Accuracy= 0.96094\n",
      "RELU: Nbr of updates: 45, Minibatch Loss= 0.444580, Training Accuracy= 0.90625\n",
      "SNN: Nbr of updates: 45, Minibatch Loss= 0.254133, Training Accuracy= 0.92969\n",
      "RELU: Nbr of updates: 46, Minibatch Loss= 0.437425, Training Accuracy= 0.85938\n",
      "SNN: Nbr of updates: 46, Minibatch Loss= 0.162577, Training Accuracy= 0.97656\n",
      "RELU: Nbr of updates: 47, Minibatch Loss= 0.357991, Training Accuracy= 0.91406\n",
      "SNN: Nbr of updates: 47, Minibatch Loss= 0.140877, Training Accuracy= 0.97656\n",
      "RELU: Nbr of updates: 48, Minibatch Loss= 0.439970, Training Accuracy= 0.89062\n",
      "SNN: Nbr of updates: 48, Minibatch Loss= 0.210475, Training Accuracy= 0.94531\n",
      "RELU: Nbr of updates: 49, Minibatch Loss= 0.361864, Training Accuracy= 0.90625\n",
      "SNN: Nbr of updates: 49, Minibatch Loss= 0.212902, Training Accuracy= 0.96875\n",
      "RELU: Nbr of updates: 50, Minibatch Loss= 0.361003, Training Accuracy= 0.90625\n",
      "SNN: Nbr of updates: 50, Minibatch Loss= 0.126570, Training Accuracy= 0.98438\n",
      "Optimization Finished!\n",
      "\n",
      "ReLU: Testing Accuracy: 0.855469\n",
      "SNN: Testing Accuracy: 0.927734\n"
     ]
    }
   ],
   "source": [
    "# Launch the graph\n",
    "gpu_options = tf.GPUOptions(allow_growth=True)\n",
    "with tf.Session(config=tf.ConfigProto(gpu_options=gpu_options)) as sess:\n",
    "    sess.run(init)\n",
    "    step = 0\n",
    "    # Keep training until reach max iterations\n",
    "    while step < training_iters:\n",
    "        batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "        batch_x_norm = scaler.transform(batch_x)\n",
    "        # Run optimization op (backprop)\n",
    "        sess.run(optimizer_ReLU, feed_dict={x: batch_x, y: batch_y,\n",
    "                                       keep_prob: keep_prob_ReLU})\n",
    "        sess.run(optimizer_SNN, feed_dict={x: batch_x_norm, y: batch_y,\n",
    "                                       dropout_prob: dropout_prob_SNN})\n",
    "        \n",
    "        \n",
    "        if step % display_step == 0:\n",
    "            #batch_x, batch_y = mnist.test.next_batch(batch_size)\n",
    "            #batch_x_norm = scaler.transform(batch_x)\n",
    "            # Calculate batch loss and accuracy\n",
    "            loss_ReLU, acc_ReLU = sess.run([cost_ReLU, accuracy_ReLU], feed_dict={x: batch_x,\n",
    "                                                              y: batch_y,\n",
    "                                                              keep_prob: 1.0})\n",
    "            training_loss_protocol_ReLU.append(loss_ReLU)\n",
    "            \n",
    "            loss_SNN, acc_SNN = sess.run([cost_SNN, accuracy_SNN], feed_dict={x: batch_x_norm,\n",
    "                                                              y: batch_y,\n",
    "                                                              dropout_prob: 0.0})\n",
    "            training_loss_protocol_SNN.append(loss_SNN)\n",
    "            \n",
    "            print( \"RELU: Nbr of updates: \" + str(step+1) + \", Minibatch Loss= \" + \\\n",
    "                  \"{:.6f}\".format(loss_ReLU) + \", Training Accuracy= \" + \\\n",
    "                  \"{:.5f}\".format(acc_ReLU))\n",
    "            \n",
    "            print( \"SNN: Nbr of updates: \" + str(step+1) + \", Minibatch Loss= \" + \\\n",
    "                  \"{:.6f}\".format(loss_SNN) + \", Training Accuracy= \" + \\\n",
    "                  \"{:.5f}\".format(acc_SNN))\n",
    "        step += 1\n",
    "    print(\"Optimization Finished!\\n\")\n",
    "\n",
    "    # Calculate accuracy for 256 mnist test images\n",
    "    print(\"ReLU: Testing Accuracy:\", sess.run(accuracy_ReLU, feed_dict={x: mnist.test.images[:512],\n",
    "                                      y: mnist.test.labels[:512],\n",
    "                                      keep_prob: 1.0}))\n",
    "    print(\"SNN: Testing Accuracy:\", sess.run(accuracy_SNN, feed_dict={x: scaler.transform(mnist.test.images[:512]),\n",
    "                                      y: mnist.test.labels[:512],\n",
    "                                      dropout_prob: 0.0}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAagAAAEYCAYAAAAJeGK1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nCJf0/zsa/QiX5dWJAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fb0d68e0400>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot( training_loss_protocol_ReLU, label='Loss ReLU')\n",
    "ax.plot( training_loss_protocol_SNN, label='Loss SNN')\n",
    "ax.set_yscale('log')  # log scale\n",
    "fig.tight_layout()\n",
    "fig"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-alpha",
   "language": "python",
   "name": "tf-alpha"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
